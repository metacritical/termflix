From 3b49dd8214721dcc26a35eb5002ee98012e4398f Mon Sep 17 00:00:00 2001
From: metacritical <pankajdoharey@gmail.com>
Date: Wed, 24 Dec 2025 01:03:37 +0530
Subject: [PATCH] feat: Refactor movie fetching with TPB Top 100 + YTS
 enrichment
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

- Add new fetch_enriched_catalog() algorithm:
 - Fetches TPB Top 100 HD movies as base
 - Enriches each movie with TPB + YTS search
 - Fetches YTS pages 1-10 for latest content
 - Deduplicates by normalized title
 - Sorts by year (desc), then seeds (desc)

- Add clean_display_title() function to fix dirty TPB titles:
 - Removes quality markers: [1080p], [WEBRip], [5.1]
 - Removes codec info: x264, x265, HEVC, HDRip
 - Removes release groups: -BONE, -RARBG, -YTS
 - Fixes 'Predator Badlands (2025) [1080p] [WEBRip]' â†’ 'Predator Badlands (2025)'

- Update preview_fzf.sh clean_title_for_api:
 - Now removes all quality/codec markers before TMDB/OMDB lookup
 - Fixes poster fetching for cached dirty titles

- Add get_enriched_catalog() bash wrapper in fetching.sh
- Update catalog.sh with enriched mode detection
- Update bin/termflix to use enriched mode by default
---
 bin/termflix                                 |  18 +-
 modules/catalog.sh                           |  56 ++
 modules/catalog/fetching.sh                  |  32 +-
 modules/ui/catalog/preview_fzf.sh            |  14 +-
 scripts/python/fetch_multi_source_catalog.py | 507 ++++++++++++++-----
 5 files changed, 503 insertions(+), 124 deletions(-)

diff --git a/bin/termflix b/bin/termflix
index c7c1f7c..fc4a67d 100755
--- a/bin/termflix
+++ b/bin/termflix
@@ -312,13 +312,20 @@ main() {
         
         case "$type" in
             movies)
-                display_catalog "$icon $label Movies" get_latest_movies 50
+                # Use new enriched catalog (TPB top 100 + YTS pages)
+                export TERMFLIX_USE_ENRICHED=true
+                export CURRENT_CATEGORY=movies
+                display_catalog "$icon $label Movies" get_enriched_catalog 10 movies
                 ;;
             shows)
+                export CURRENT_CATEGORY=shows
                 display_catalog "$icon $label TV Shows" get_latest_shows 50
                 ;;
             all|*)
-                display_catalog "$icon $label" get_latest_movies 50
+                # Default to enriched catalog for all
+                export TERMFLIX_USE_ENRICHED=true
+                export CURRENT_CATEGORY=movies
+                display_catalog "$icon $label" get_enriched_catalog 10 movies
                 ;;
         esac
         exit $?
@@ -353,8 +360,11 @@ main() {
                 echo "Usage: torrent catalog <genre>"
                 exit 1
             fi
-            # TPB only - YTS disabled for genre search
-            display_catalog "ğŸ“š $genre Movies" get_latest_movies 50
+            # TPB + YTS - Use enriched catalog with genre filter
+            export TERMFLIX_USE_ENRICHED=true
+            export CURRENT_CATEGORY=movies
+            export CURRENT_GENRE="$genre"
+            display_catalog "ğŸ“š $genre Movies" get_enriched_catalog 10 movies
             exit $?
             ;;
         search)
diff --git a/modules/catalog.sh b/modules/catalog.sh
index f67bb9a..8366f63 100644
--- a/modules/catalog.sh
+++ b/modules/catalog.sh
@@ -104,6 +104,60 @@ display_catalog() {
     if [ "$goto_pagination" != "true" ]; then
         echo -e "${CYAN}Fetching data from sources...${RESET}"
         
+        # Check if we're using the new enriched catalog (single call)
+        local first_func="${args_copy[0]}"
+        local use_enriched=false
+        
+        # More robust check: function name contains "enriched" OR env var is true
+        if [[ "$first_func" == *"enriched"* ]] || [[ "${TERMFLIX_USE_ENRICHED:-}" == "true" ]]; then
+            use_enriched=true
+        fi
+        
+        if [ "$use_enriched" = true ]; then
+            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+            # NEW ENRICHED ALGORITHM: Single call fetches TPB top 100 + YTS pages
+            # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+            local yts_pages="${TERMFLIX_INITIAL_YTS_PAGES:-10}"
+            local category="${CURRENT_CATEGORY:-movies}"
+            
+            echo -e "${MAGENTA}ğŸ“¦ Loading TPB Top 100 + YTS pages 1-${yts_pages}...${RESET}"
+            
+            # Single call fetches everything
+            get_enriched_catalog "$yts_pages" "$category" > "$temp_file" 2>/dev/null
+            local fetch_status=$?
+            
+            if [ $fetch_status -eq 0 ] && [ -s "$temp_file" ]; then
+                printf "\r${GREEN}âœ“ Fetched enriched catalog (TPB top 100 + YTS 1-${yts_pages})${RESET}                    \n"
+            else
+                printf "\r${YELLOW}âš  Enriched fetch failed, falling back to legacy...${RESET}\n"
+                use_enriched=false
+            fi
+            
+            # Background prefetch YTS pages 11-20
+            local prefetch_start=$((yts_pages + 1))
+            local prefetch_end=$((yts_pages + 10))
+            echo ""
+            echo -e "${GRAY}ğŸ“¥ Prefetching YTS pages ${prefetch_start}-${prefetch_end} in background...${RESET}"
+            
+            (
+                # Append additional YTS pages to temp file
+                local script_path="${TERMFLIX_SCRIPTS_DIR:-$(dirname "${BASH_SOURCE[0]}")/../scripts/python}/fetch_multi_source_catalog.py"
+                if [[ -f "$script_path" ]]; then
+                    python3 "$script_path" --yts-pages "$prefetch_end" --category "$category" 2>/dev/null >> "$temp_file"
+                fi
+            ) &
+            local prefetch_pid=$!
+            
+            export TERMFLIX_PREFETCH_PID=$prefetch_pid
+            export TERMFLIX_BATCH_END=$prefetch_end
+            export TERMFLIX_SOURCE_NAME="enriched"
+            export TERMFLIX_TEMP_FILE="$temp_file"
+            export TERMFLIX_INITIAL_PAGES=$yts_pages
+        fi
+        
+        # Fall back to legacy per-page fetching if not enriched
+        if [ "$use_enriched" = false ]; then
+        
         # SMART PREFETCH STRATEGY:
         # Phase 1: Load pages 1-5 synchronously (fast startup ~5 sec)
         # Phase 2: Background fetch pages 6-15 (10 more pages)
@@ -212,6 +266,8 @@ display_catalog() {
         
         printf "\r${GREEN}âœ“ Fetched all pages${RESET}                    \n"
         
+        fi  # End legacy per-page fetch
+        
         
         echo -e "${CYAN}Parsing results...${RESET}"
         
diff --git a/modules/catalog/fetching.sh b/modules/catalog/fetching.sh
index 07e0012..8333a10 100644
--- a/modules/catalog/fetching.sh
+++ b/modules/catalog/fetching.sh
@@ -323,5 +323,35 @@ get_latest_all() {
     done
 }
 
+# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+# NEW ENRICHED CATALOG - Single call fetches all (TPB top100 + YTS pages)
+# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+get_enriched_catalog() {
+    local yts_pages="${1:-10}"
+    local category="${2:-movies}"
+    
+    local extra_args=""
+    [[ "$FORCE_REFRESH" == "true" ]] && extra_args+=" --refresh"
+    [[ -n "$CURRENT_QUERY" ]] && extra_args+=" --query \"$CURRENT_QUERY\""
+    [[ -n "$CURRENT_GENRE" ]] && extra_args+=" --genre \"$CURRENT_GENRE\""
+    [[ -n "$CURRENT_MIN_RATING" ]] && extra_args+=" --min-rating $CURRENT_MIN_RATING"
+    [[ -n "$CURRENT_SORT" ]] && extra_args+=" --sort $CURRENT_SORT"
+    [[ -n "$CURRENT_ORDER" ]] && extra_args+=" --order-by $CURRENT_ORDER"
+    
+    local script_path="${CATALOG_HELPER_SCRIPTS_DIR}/fetch_multi_source_catalog.py"
+    
+    if [[ -f "$script_path" ]] && command -v python3 &>/dev/null; then
+        python3 "$script_path" \
+            --yts-pages "$yts_pages" \
+            --category "$category" \
+            $extra_args 2>/dev/null
+        return $?
+    fi
+    
+    # Fallback to old per-page method
+    get_latest_movies 50 1
+}
+
 # Export catalog fetching functions
-export -f get_latest_movies get_trending_movies get_popular_movies get_latest_shows get_catalog_by_genre get_new_48h_movies get_latest_all
+export -f get_latest_movies get_trending_movies get_popular_movies get_latest_shows get_catalog_by_genre get_new_48h_movies get_latest_all get_enriched_catalog
+
diff --git a/modules/ui/catalog/preview_fzf.sh b/modules/ui/catalog/preview_fzf.sh
index 759ec46..6ddbb18 100755
--- a/modules/ui/catalog/preview_fzf.sh
+++ b/modules/ui/catalog/preview_fzf.sh
@@ -64,7 +64,19 @@ movie_year=""
 if [[ "$title" =~ (19[0-9]{2}|20[0-9]{2}) ]]; then
     movie_year="${BASH_REMATCH[1]}"
 fi
-clean_title_for_api=$(echo "$title" | sed -E 's/\[SERIES\]//gi; s/\((19|20)[0-9]{2}\)//g; s/[[:space:]]+(19|20)[0-9]{2}//g; s/[[:space:]]+$//; s/^[[:space:]]+//')
+# Clean title for API lookups - remove all quality markers, brackets, codec info
+clean_title_for_api="$title"
+# Remove bracketed content like [1080p], [WEBRip], [5.1], [SERIES]
+clean_title_for_api=$(echo "$clean_title_for_api" | sed -E 's/\[[^]]*\]//g')
+# Remove quality/codec markers
+clean_title_for_api=$(echo "$clean_title_for_api" | sed -E 's/[[:space:]]+(1080p|720p|480p|2160p|4K|HDRip|BRRip|BluRay|WEB-DL|WEBRip|HDTV|x264|x265|HEVC|AAC|DTS|10bit|HDR|REMUX)([[:space:]]|$)/ /gi')
+# Remove release group at end (e.g., -YTS, -RARBG)
+clean_title_for_api=$(echo "$clean_title_for_api" | sed -E 's/[[:space:]]*-[A-Za-z0-9]+$//')
+# Remove year (we add it back separately if needed)
+clean_title_for_api=$(echo "$clean_title_for_api" | sed -E 's/\((19|20)[0-9]{2}\)//g; s/[[:space:]]+(19|20)[0-9]{2}//g')
+# Trim whitespace
+clean_title_for_api=$(echo "$clean_title_for_api" | sed -E 's/[[:space:]]+/ /g; s/^[[:space:]]+//; s/[[:space:]]+$//')
+
 
 # Sanitize display title
 display_title="$title"
diff --git a/scripts/python/fetch_multi_source_catalog.py b/scripts/python/fetch_multi_source_catalog.py
index d49cfcb..6c6de18 100644
--- a/scripts/python/fetch_multi_source_catalog.py
+++ b/scripts/python/fetch_multi_source_catalog.py
@@ -712,19 +712,207 @@ def group_movies_by_title(items: List[Dict], limit: int) -> List[str]:
     return results
 
 # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-# MULTI-SOURCE AGGREGATION
+# NEW ENRICHED CATALOG ALGORITHM
 # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 
+def normalize_movie_title(name: str) -> str:
+    """Normalize movie title for deduplication (lowercase, stripped)."""
+    # Remove quality markers, release groups, etc.
+    name = re.sub(r'[\.\s]+(1080p|720p|480p|2160p|4K|HDRip|BRRip|BluRay|WEB-DL|WEBRip|HDTV|x264|x265|HEVC|AAC|DTS)', '', name, flags=re.IGNORECASE)
+    name = re.sub(r'-[A-Za-z0-9]+$', '', name)  # Release group
+    name = re.sub(r'\[.*?\]', '', name)  # Bracketed content
+    name = re.sub(r'\((?!(?:19|20)\d{2}\))[^)]*\)', '', name)  # Parentheses except year
+    name = name.replace('.', ' ').replace('_', ' ')
+    name = re.sub(r'\s+', ' ', name).strip()
+    return name.lower()
+
+
+def clean_display_title(name: str) -> str:
+    """
+    Clean TPB torrent name for display and API lookups.
+    Removes quality markers like [1080p], [WEBRip], [5.1] etc.
+    Preserves the year in parentheses.
+    
+    Examples:
+        "Predator Badlands (2025) [1080p] [WEBRip]" -> "Predator Badlands (2025)"
+        "The.Running.Man.2025.1080p.WEBRip.x264" -> "The Running Man (2025)"
+        "Predator Badlands HDrip x265-BONE" -> "Predator Badlands"
+    """
+    # Remove bracketed content like [1080p], [WEBRip], [5.1], [YTS.MX]
+    name = re.sub(r'\s*\[.*?\]', '', name)
+    
+    # Replace dots with spaces (common in torrent names)
+    name = name.replace('.', ' ')
+    name = name.replace('_', ' ')
+    
+    # Extended quality/codec pattern - comprehensive list
+    codec_patterns = [
+        # Quality markers
+        r'1080p', r'720p', r'480p', r'2160p', r'4K', r'UHD',
+        # Source types
+        r'HDRip', r'BRRip', r'BluRay', r'BDRip', r'DVDRip', r'WEB-DL', r'WEBRip', r'HDTV', r'CAM', r'TS', r'TC', r'HDCAM', r'SCR',
+        # Video codecs
+        r'x264', r'x265', r'HEVC', r'H\.?264', r'H\.?265', r'XviD', r'DivX', r'AV1', r'VP9',
+        # Audio codecs
+        r'AAC', r'DTS', r'AC3', r'DD5\.?1', r'DD7\.?1', r'ATMOS', r'TrueHD', r'LPCM',
+        # Other markers
+        r'10bit', r'8bit', r'HDR', r'HDR10', r'SDR', r'REMUX', r'PROPER', r'REPACK', r'EXTENDED', r'UNCUT', r'THEATRICAL',
+        # Common release groups (these often appear without hyphen in name)
+        r'RARBG', r'YTS', r'YIFY', r'MX', r'BONE', r'SPARKS', r'GECKOS', r'FGT', r'EVO', r'AMZN', r'NTb',
+    ]
+    
+    # Build regex pattern
+    codec_regex = r'\b(' + '|'.join(codec_patterns) + r')\b'
+    name = re.sub(codec_regex, ' ', name, flags=re.IGNORECASE)
+    
+    # Remove release group at end (e.g., -YTS, -RARBG, -MeGusta)
+    name = re.sub(r'\s*-[A-Za-z0-9]+$', '', name)
+    
+    # Remove trailing release group names without hyphen
+    name = re.sub(r'\s+(BONE|RARBG|YTS|YIFY|MX|SPARKS|GECKOS|FGT|EVO|AMZN|NTb)\s*$', '', name, flags=re.IGNORECASE)
+    
+    # Extract year if present in the name (not in parentheses yet)
+    # Pattern: "Movie Title 2025" -> keep as is if year exists
+    year_match = re.search(r'\(?(19|20)\d{2}\)?', name)
+    year = year_match.group(0).strip('()') if year_match else None
+    
+    # If year exists but not in parentheses, format it properly
+    if year:
+        # Remove year from anywhere and add it properly at the end
+        name = re.sub(r'\s*\(?' + year + r'\)?\s*', ' ', name)
+        name = name.strip()
+        # Remove trailing punctuation (hyphens, colons) that remain after cleaning
+        name = re.sub(r'[\s\-:]+$', '', name)
+        name = f"{name} ({year})"
+    
+    # Clean up multiple spaces and trailing punctuation
+    name = re.sub(r'\s+', ' ', name).strip()
+    name = re.sub(r'[\s\-:]+$', '', name)  # Final cleanup of trailing punct
+    
+    # Title case for cleaner display
+    name = name.title()
+    
+    # Fix common title case issues
+    name = re.sub(r'\bOf\b', 'of', name)
+    name = re.sub(r'\bThe\b', 'The', name)
+    name = re.sub(r'\bA\b', 'a', name)
+    name = re.sub(r'\bAn\b', 'an', name)
+    name = re.sub(r'\bAnd\b', 'and', name)
+    name = re.sub(r'\bIn\b', 'in', name)
+    name = re.sub(r'\bOn\b', 'on', name)
+    name = re.sub(r'\bTo\b', 'to', name)
+    name = re.sub(r'\bFor\b', 'for', name)
+    # But capitalize at start of title
+    if name:
+        name = name[0].upper() + name[1:]
+    
+    return name
+
+def fetch_tpb_top100_movies() -> List[Dict]:
+    """
+    Fetch TPB top 100 HD movies (precompiled).
+    Returns list of dicts with normalized fields.
+    """
+    TPB_TOP100_URL = 'https://apibay.org/precompiled/data_top100_207.json'
+    response = fetch_url(TPB_TOP100_URL, timeout=10)
+    if not response:
+        return []
+    
+    try:
+        data = json.loads(response)
+        movies = []
+        
+        # Regex to detect TV Shows
+        tv_pattern = re.compile(r'(S\d{1,2}E\d{1,2}|Season\s*\d+|Complete\s*Series|\d+x\d+)', re.IGNORECASE)
+        
+        for item in data[:100]:
+            info_hash = item.get('info_hash', '')
+            if not info_hash or info_hash == '0' * 40:
+                continue
+            
+            name = item.get('name', 'Unknown')
+            
+            # Skip TV shows
+            if tv_pattern.search(name):
+                continue
+            
+            # Extract year from name
+            year_match = re.search(r'(19|20)\d{2}', name)
+            year = year_match.group(0) if year_match else ''
+            
+            # Generate clean search title for YTS/API lookups
+            cleaned = clean_display_title(name)
+            # Extract just the title part (without year) for searching
+            search_title = re.sub(r'\s*\(\d{4}\)\s*$', '', cleaned).strip()
+            
+            movies.append({
+                'name': name,
+                'clean_title': search_title.lower(),  # For deduplication
+                'search_title': search_title,          # For YTS/TPB search
+                'display_name': cleaned,               # For display (with year)
+                'year': year,
+                'info_hash': info_hash.lower(),
+                'seeders': int(item.get('seeders', 0)),
+                'size': int(item.get('size', 0)),
+                'imdb': item.get('imdb', ''),
+                'source': 'TPB'
+            })
+        
+        return movies
+    except Exception:
+        return []
+
+
+def enrich_movie_with_sources(movie: Dict) -> Dict:
+    """
+    Enrich a movie with additional sources from TPB search and YTS search.
+    Returns movie dict with 'torrents' list containing all sources.
+    """
+    # Use search_title if available (from TPB), otherwise clean_title
+    title = movie.get('search_title', movie.get('clean_title', movie.get('name', '')))
+    year = movie.get('year', '')
+    search_query = f"{title} {year}".strip()
+    
+    torrents = []
+    
+    # Add original TPB torrent if present
+    if movie.get('info_hash'):
+        size_bytes = int(movie.get('size', 0))
+        size_mb = size_bytes // (1024 * 1024)
+        torrents.append({
+            'source': 'TPB',
+            'hash': movie['info_hash'],
+            'quality': extract_quality(movie.get('name', '')),
+            'size': f"{size_mb}MB" if size_mb < 1024 else f"{size_mb/1024:.1f}GB",
+            'seeds': movie.get('seeders', 0),
+            'magnet': f"magnet:?xt=urn:btih:{movie['info_hash']}"
+        })
+    
+    # Search TPB for more sources
+    tpb_results = search_tpb(search_query, category=207)
+    for t in tpb_results:
+        if t.get('hash') and t['hash'] not in [x['hash'] for x in torrents]:
+            torrents.append(t)
+    
+    # Search YTS for sources
+    yts_results = search_yts(search_query)
+    for t in yts_results:
+        if t.get('hash') and t['hash'] not in [x['hash'] for x in torrents]:
+            torrents.append(t)
+    
+    movie['torrents'] = torrents
+    return movie
+
+
 def aggregate_movie(movie: Dict) -> Optional[str]:
     """
-    Aggregate torrents from YTS and TPB for a single movie.
+    Aggregate torrents from YTS and TPB for a single movie (for search).
     Returns COMBINED format string.
     """
     title = movie.get('title', '')
     year = movie.get('year', '')
     poster = movie.get('medium_cover_image', 'N/A')
-    imdb_id = movie.get('imdb_code', '')
-    rating = movie.get('rating', 0)  # Use rating instead of IMDB ID
+    rating = movie.get('rating', 0)
     
     if not title:
         return None
@@ -738,19 +926,11 @@ def aggregate_movie(movie: Dict) -> Optional[str]:
     # Search TPB for additional torrents
     tpb_torrents = search_tpb(search_query)
     
-    # Also search YTS for more quality options
-    yts_search_torrents = search_yts(search_query)
-    
     # Deduplicate by hash
     seen_hashes = {t['hash'] for t in all_torrents}
     
     for t in tpb_torrents:
-        if t['hash'] not in seen_hashes and t.get('source'):
-            all_torrents.append(t)
-            seen_hashes.add(t['hash'])
-    
-    for t in yts_search_torrents:
-        if t['hash'] not in seen_hashes and t.get('source'):
+        if t.get('hash') and t['hash'] not in seen_hashes and t.get('source'):
             all_torrents.append(t)
             seen_hashes.add(t['hash'])
     
@@ -764,28 +944,23 @@ def aggregate_movie(movie: Dict) -> Optional[str]:
         return None
     
     # Sort by seeds (descending)
-    all_torrents.sort(key=lambda x: x['seeds'], reverse=True)
+    all_torrents.sort(key=lambda x: x.get('seeds', 0), reverse=True)
     
-    # Format arrays for COMBINED output - PER-TORRENT data (not unique sources!)
-    # Each array must have the same length as torrents
-    per_torrent_sources = [t['source'] for t in all_torrents]  # Per-torrent source
-    qualities = [t['quality'] for t in all_torrents]
-    seeds = [str(t['seeds']) for t in all_torrents]
-    sizes = [t['size'] for t in all_torrents]
-    magnets = [t['magnet'] for t in all_torrents]
+    # Format arrays for COMBINED output
+    per_torrent_sources = [t['source'] for t in all_torrents]
+    qualities = [t.get('quality', 'Unknown') for t in all_torrents]
+    seeds = [str(t.get('seeds', 0)) for t in all_torrents]
+    sizes = [t.get('size', 'N/A') for t in all_torrents]
+    magnets = [t.get('magnet', '') for t in all_torrents]
     
-    # Format rating for display
     rating_str = f"{rating}/10" if rating else 'N/A'
-    
-    # Extract Genres
     genres = movie.get('genres', [])
     genre_str = ', '.join(genres) if genres else 'Unknown'
     
-    # Build COMBINED line
     display_title = f"{title} ({year})"
     combined = (
         f"COMBINED|{display_title}|"
-        f"{'^'.join(per_torrent_sources)}|"  # Per-torrent sources
+        f"{'^'.join(per_torrent_sources)}|"
         f"{'^'.join(qualities)}|"
         f"{'^'.join(seeds)}|"
         f"{'^'.join(sizes)}|"
@@ -798,127 +973,223 @@ def aggregate_movie(movie: Dict) -> Optional[str]:
     
     return combined
 
-def fetch_multi_source_catalog(limit: int = 50, page: int = 1, parallel: bool = True, sort_by: str = 'date_added',
-                               query_term: str = None, genre: str = None, min_rating: int = 0,
-                               order_by: str = 'desc', category_mode: str = 'movies') -> List[str]:
+
+def fetch_enriched_catalog(limit: int = 50, page: int = 1, sort_by: str = 'date_added',
+                           query_term: str = None, genre: str = None, min_rating: int = 0,
+                           order_by: str = 'desc', category_mode: str = 'movies',
+                           yts_pages: int = 10) -> List[str]:
     """
-    Fetch movies from YTS and enrich each with TPB torrents.
+    NEW ALGORITHM:
+    1. Fetch TPB top 100 HD movies (popular/trending base)
+    2. For each: search TPB + YTS for all sources
+    3. Fetch YTS pages 1-10 (or custom) for latest content
+    4. Combine, dedupe by normalized title, sort
+    5. Return COMBINED format strings
     
     Args:
-        limit: Movies per page
-        page: Page number
-        parallel: Use parallel fetching
-        sort_by: Sort method ('date_added', 'download_count', 'rating', 'seeds', 'peers', 'year')
-        query_term: Search query
-        genre: Genre filter
-        min_rating: Minimum rating filter
-        order_by: Sort order ('desc' or 'asc')
-        category_mode: 'movies' or 'shows'
-    
-    Returns list of COMBINED format strings.
+        limit: Items per page for display
+        page: Page number for display
+        yts_pages: Number of YTS pages to fetch (default 10)
     """
-    # If query is provided, perform a targeted search instead of fetching newest
+    # Handle search queries separately
     if query_term:
         if category_mode == 'movies':
-            # Movies: Search YTS first
-            movies = fetch_yts_movies(limit=limit, page=page, sort_by=sort_by, 
+            movies = fetch_yts_movies(limit=limit, page=page, sort_by=sort_by,
                                       query_term=query_term, genre=genre, min_rating=min_rating,
                                       order_by=order_by)
             if not movies:
-                # Fallback: Search TPB Movies
-                tpb_cat = 207 # HD Movies
-                items = search_tpb(query_term, category=tpb_cat)
-                return group_movies_by_title(items, limit)
+                items = search_tpb(query_term, category=207)
+                return group_movies_by_title([{'source': 'TPB', **i} for i in items], limit)
+            
+            results = []
+            for movie in movies:
+                result = aggregate_movie(movie)
+                if result:
+                    results.append(result)
+            return results
         else:
-            # Shows: Search TPB Shows - return INDIVIDUAL torrents for version picker
-            tpb_cat = 208  # HD TV Shows
+            # Shows search
+            tpb_cat = 208
             items = search_tpb(query_term, category=tpb_cat)
-            # For episode search, return each torrent as a separate COMBINED entry (like movies)
-            # This allows the version picker to list individual quality options
             results = []
             for item in items[:limit]:
                 name = item.get('name', 'Unknown')
                 quality = item.get('quality', extract_quality(name))
-                seeds = str(item.get('seeds', 0))
-                size = item.get('size', 'N/A')
-                magnet = item.get('magnet', '')
-                
                 combined = (
                     f"COMBINED|{name}|"
-                    f"TPB|"
-                    f"{quality}|"
-                    f"{seeds}|"
-                    f"{size}|"
-                    f"{magnet}|"
-                    f"N/A|"
-                    f"N/A|"
-                    f"Shows|"
-                    f"1"
+                    f"TPB|{quality}|{item.get('seeds', 0)}|{item.get('size', 'N/A')}|"
+                    f"{item.get('magnet', '')}|N/A|N/A|Shows|1"
                 )
                 results.append(combined)
             return results
-
-    # NO QUERY: Fetch Latest/Trending Catalog
-    movies = []
-    if category_mode == 'movies':
-        movies = fetch_yts_movies(limit=limit, page=page, sort_by=sort_by, 
-                                  query_term=query_term, genre=genre, min_rating=min_rating,
-                                  order_by=order_by)
     
-    # FALLBACK: If YTS fails or we want SHOWS, use TPB precompiled (Newest)
-    if not movies:
-        # Determine TPB Category
-        tpb_cat = 207  # Default HD Movies
-        if category_mode == 'shows':
-            tpb_cat = 208 # HD TV Shows
-        
-        return fetch_tpb_fallback_catalog(limit, category=tpb_cat)
+    # Handle TV Shows separately (use existing logic)
+    if category_mode == 'shows':
+        return fetch_tpb_fallback_catalog(limit * 2, category=208)
     
-    results = []
+    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+    # PHASE 1: Fetch TPB Top 100 Movies
+    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+    all_movies = {}  # Keyed by normalized title for deduplication
     
-    if parallel:
-        # Parallel aggregation (faster)
-        with ThreadPoolExecutor(max_workers=10) as executor:
-            futures = {executor.submit(aggregate_movie, m): m for m in movies}
-            for future in as_completed(futures):
-                try:
-                    result = future.result()
-                    if result:
-                        results.append(result)
-                except Exception:
-                    pass
-    else:
-        # Sequential (slower but simpler)
+    tpb_top100 = fetch_tpb_top100_movies()
+    
+    # Enrich TPB movies with additional sources (parallel)
+    with ThreadPoolExecutor(max_workers=15) as executor:
+        futures = {executor.submit(enrich_movie_with_sources, m): m for m in tpb_top100}
+        for future in as_completed(futures, timeout=30):
+            try:
+                enriched = future.result(timeout=5)
+                if enriched and enriched.get('torrents'):
+                    key = normalize_movie_title(enriched.get('name', ''))
+                    if key not in all_movies:
+                        all_movies[key] = enriched
+                    else:
+                        # Merge torrents
+                        existing_hashes = {t['hash'] for t in all_movies[key].get('torrents', [])}
+                        for t in enriched.get('torrents', []):
+                            if t['hash'] not in existing_hashes:
+                                all_movies[key]['torrents'].append(t)
+            except Exception:
+                pass
+    
+    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+    # PHASE 2: Fetch YTS Latest Pages 1-N
+    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+    def fetch_and_enrich_yts_page(p: int) -> List[Dict]:
+        """Fetch a YTS page and enrich each movie."""
+        movies = fetch_yts_movies(limit=50, page=p, sort_by=sort_by, 
+                                  genre=genre, min_rating=min_rating, order_by=order_by)
+        enriched = []
         for movie in movies:
-            result = aggregate_movie(movie)
-            if result:
-                results.append(result)
+            title = movie.get('title', '')
+            year = movie.get('year', '')
+            
+            # Parse YTS torrents
+            torrents = parse_yts_torrents(movie)
+            
+            # Search TPB for additional sources
+            tpb_results = search_tpb(f"{title} {year}", category=207)
+            seen_hashes = {t['hash'] for t in torrents}
+            for t in tpb_results:
+                if t.get('hash') and t['hash'] not in seen_hashes:
+                    torrents.append(t)
+                    seen_hashes.add(t['hash'])
+            
+            enriched.append({
+                'name': f"{title} ({year})",
+                'clean_title': title.lower(),
+                'year': str(year),
+                'torrents': torrents,
+                'poster': movie.get('medium_cover_image', 'N/A'),
+                'rating': movie.get('rating', 0),
+                'genres': movie.get('genres', []),
+                'imdb': movie.get('imdb_code', '')
+            })
+        return enriched
+    
+    # Parallel fetch YTS pages
+    with ThreadPoolExecutor(max_workers=10) as executor:
+        futures = {executor.submit(fetch_and_enrich_yts_page, p): p for p in range(1, yts_pages + 1)}
+        for future in as_completed(futures, timeout=60):
+            try:
+                page_movies = future.result(timeout=15)
+                for movie in page_movies:
+                    key = normalize_movie_title(movie.get('name', ''))
+                    if key not in all_movies:
+                        all_movies[key] = movie
+                    else:
+                        # Merge torrents and prefer YTS metadata (has poster, rating, etc.)
+                        existing = all_movies[key]
+                        existing_hashes = {t['hash'] for t in existing.get('torrents', [])}
+                        for t in movie.get('torrents', []):
+                            if t['hash'] not in existing_hashes:
+                                existing['torrents'].append(t)
+                        # Update metadata if YTS has better info
+                        if movie.get('poster') and movie['poster'] != 'N/A':
+                            existing['poster'] = movie['poster']
+                        if movie.get('rating'):
+                            existing['rating'] = movie['rating']
+                        if movie.get('genres'):
+                            existing['genres'] = movie['genres']
+            except Exception:
+                pass
+    
+    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+    # PHASE 3: Convert to COMBINED format
+    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+    results = []
     
-    # Feature 8: Year-Based Sorting
+    for key, movie in all_movies.items():
+        torrents = movie.get('torrents', [])
+        if not torrents:
+            continue
+        
+        # Sort torrents by seeds
+        torrents.sort(key=lambda x: int(x.get('seeds', 0)), reverse=True)
+        
+        # Build COMBINED arrays
+        sources = [t['source'] for t in torrents]
+        qualities = [t.get('quality', 'Unknown') for t in torrents]
+        seeds = [str(t.get('seeds', 0)) for t in torrents]
+        sizes = [t.get('size', 'N/A') for t in torrents]
+        magnets = [t.get('magnet', '') for t in torrents]
+        
+        # Get metadata
+        poster = movie.get('poster', 'N/A')
+        rating = movie.get('rating', 0)
+        rating_str = f"{rating}/10" if rating else 'N/A'
+        genres = movie.get('genres', [])
+        genre_str = ', '.join(genres) if genres else 'Unknown'
+        
+        # Clean the display title (removes [1080p] [WEBRip] etc.)
+        raw_title = movie.get('name', key)
+        display_title = clean_display_title(raw_title)
+        
+        combined = (
+            f"COMBINED|{display_title}|"
+            f"{'^'.join(sources)}|"
+            f"{'^'.join(qualities)}|"
+            f"{'^'.join(seeds)}|"
+            f"{'^'.join(sizes)}|"
+            f"{'^'.join(magnets)}|"
+            f"{poster}|"
+            f"{rating_str}|"
+            f"{genre_str}|"
+            f"{len(torrents)}"
+        )
+        results.append(combined)
     
+    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
+    # PHASE 4: Sort by year (newest first), then by max seeds
+    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
     def extract_year_from_combined(entry):
-        # Format: COMBINED|Title (YYYY)|...
         try:
-            # Extract title part (2nd field)
             parts = entry.split('|')
             if len(parts) > 1:
-                title_part = parts[1]
-                # Regex for (YYYY)
-                match = re.search(r'\((\d{4})\)', title_part)
+                match = re.search(r'\((\d{4})\)', parts[1])
                 if match:
                     return int(match.group(1))
         except:
             pass
         return 0
-
-    # Sort by Year DESC, keeping original sort order for same-year items
-    # Python sort is stable, so secondary sort (date_added/rating) is preserved
-    # Sort by Year DESC, keeping original sort order for same-year items
-    # Python sort is stable, so secondary sort (date_added/rating) is preserved
-    results.sort(key=extract_year_from_combined, reverse=True)
+    
+    def extract_max_seeds(entry):
+        try:
+            parts = entry.split('|')
+            if len(parts) > 4:
+                seeds = parts[4].split('^')
+                return max(int(s) for s in seeds if s.isdigit())
+        except:
+            pass
+        return 0
+    
+    # Sort by year desc, then by seeds desc
+    results.sort(key=lambda x: (extract_year_from_combined(x), extract_max_seeds(x)), reverse=True)
     
     return results
 
+
 # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 # MAIN
 # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@@ -926,18 +1197,18 @@ def fetch_multi_source_catalog(limit: int = 50, page: int = 1, parallel: bool =
 def main():
     import argparse
     
-    parser = argparse.ArgumentParser(description='Multi-source catalog fetcher')
-    parser.add_argument('--limit', type=int, default=50, help='Movies per page')
-    parser.add_argument('--page', type=int, default=1, help='Page number')
+    parser = argparse.ArgumentParser(description='Multi-source catalog fetcher (New Algorithm)')
+    parser.add_argument('--limit', type=int, default=50, help='Movies per display page')
+    parser.add_argument('--page', type=int, default=1, help='Display page number')
     parser.add_argument('--sort', type=str, default='date_added', 
                         choices=['date_added', 'download_count', 'rating', 'seeds', 'peers', 'year'],
                         help='Sort method')
-    parser.add_argument('--query', type=str, default=None, help='Search query (or Year)')
+    parser.add_argument('--query', type=str, default=None, help='Search query')
     parser.add_argument('--genre', type=str, default=None, help='Filter by genre')
     parser.add_argument('--min-rating', type=int, default=0, help='Minimum rating (0-9)')
     parser.add_argument('--order-by', type=str, default='desc', help='Sort order (desc/asc)')
     parser.add_argument('--category', type=str, default='movies', help='Category mode (movies/shows)')
-    parser.add_argument('--sequential', action='store_true', help='Disable parallel fetch')
+    parser.add_argument('--yts-pages', type=int, default=10, help='Number of YTS pages to fetch (default 10)')
     parser.add_argument('--refresh', action='store_true', help='Force refresh cache (ignore cached data)')
     
     args = parser.parse_args()
@@ -946,17 +1217,17 @@ def main():
     global REFRESH_CACHE
     REFRESH_CACHE = args.refresh
     
-    # 2. Fetch Catalog
-    catalog = fetch_multi_source_catalog(
+    # Fetch Catalog using NEW enriched algorithm
+    catalog = fetch_enriched_catalog(
         limit=args.limit,
         page=args.page,
-        parallel=not args.sequential,
         sort_by=args.sort,
         query_term=args.query,
         genre=args.genre,
         min_rating=args.min_rating,
         order_by=args.order_by,
-        category_mode=args.category
+        category_mode=args.category,
+        yts_pages=args.yts_pages
     )
     
     for line in catalog:
-- 
2.50.1 (Apple Git-155)

